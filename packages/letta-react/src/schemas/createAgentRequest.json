{"properties":{"name":{"type":"string","title":"Name","description":"The name of the agent."},"memory_blocks":{"anyOf":[{"items":{"properties":{"value":{"type":"string","title":"Value","description":"Value of the block."},"limit":{"type":"integer","title":"Limit","description":"Character limit of the block.","default":5000},"name":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Name","description":"Name of the block if it is a template."},"is_template":{"type":"boolean","title":"Is Template","default":false},"label":{"type":"string","title":"Label","description":"Label of the block."},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description","description":"Description of the block."},"metadata":{"anyOf":[{"additionalProperties":true,"type":"object"},{"type":"null"}],"title":"Metadata","description":"Metadata of the block.","default":{}}},"type":"object","required":["value","label"],"title":"CreateBlock","description":"Create a block","x-readme-ref-name":"CreateBlock"},"type":"array"},{"type":"null"}],"title":"Memory Blocks","description":"The blocks to create in the agent's in-context memory."},"tools":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Tools","description":"The tools used by the agent."},"tool_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Tool Ids","description":"The ids of the tools used by the agent."},"source_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Source Ids","description":"The ids of the sources used by the agent."},"block_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Block Ids","description":"The ids of the blocks used by the agent."},"tool_rules":{"anyOf":[{"items":{"oneOf":[{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"constrain_child_tools","title":"Type","default":"constrain_child_tools"},"children":{"items":{"type":"string"},"type":"array","title":"Children","description":"The children tools that can be invoked."}},"additionalProperties":false,"type":"object","required":["tool_name","children"],"title":"ChildToolRule","description":"A ToolRule represents a tool that can be invoked by the agent.","x-readme-ref-name":"ChildToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"run_first","title":"Type","default":"run_first"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"InitToolRule","description":"Represents the initial tool rule configuration.","x-readme-ref-name":"InitToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"exit_loop","title":"Type","default":"exit_loop"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"TerminalToolRule","description":"Represents a terminal tool rule configuration where if this tool gets called, it must end the agent loop.","x-readme-ref-name":"TerminalToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"conditional","title":"Type","default":"conditional"},"default_child":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Default Child","description":"The default child tool to be called. If None, any tool can be called."},"child_output_mapping":{"additionalProperties":{"type":"string"},"type":"object","title":"Child Output Mapping","description":"The output case to check for mapping"},"require_output_mapping":{"type":"boolean","title":"Require Output Mapping","description":"Whether to throw an error when output doesn't match any case","default":false}},"additionalProperties":false,"type":"object","required":["tool_name","child_output_mapping"],"title":"ConditionalToolRule","description":"A ToolRule that conditionally maps to different child tools based on the output.","x-readme-ref-name":"ConditionalToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"continue_loop","title":"Type","default":"continue_loop"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"ContinueToolRule","description":"Represents a tool rule configuration where if this tool gets called, it must continue the agent loop.","x-readme-ref-name":"ContinueToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"max_count_per_step","title":"Type","default":"max_count_per_step"},"max_count_limit":{"type":"integer","title":"Max Count Limit","description":"The max limit for the total number of times this tool can be invoked in a single step."}},"additionalProperties":false,"type":"object","required":["tool_name","max_count_limit"],"title":"MaxCountPerStepToolRule","description":"Represents a tool rule configuration which constrains the total number of times this tool can be invoked in a single step.","x-readme-ref-name":"MaxCountPerStepToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"parent_last_tool","title":"Type","default":"parent_last_tool"},"children":{"items":{"type":"string"},"type":"array","title":"Children","description":"The children tools that can be invoked."}},"additionalProperties":false,"type":"object","required":["tool_name","children"],"title":"ParentToolRule","description":"A ToolRule that only allows a child tool to be called if the parent has been called.","x-readme-ref-name":"ParentToolRule"}],"discriminator":{"propertyName":"type","mapping":{"conditional":"#/components/schemas/ConditionalToolRule","constrain_child_tools":"#/components/schemas/ChildToolRule","continue_loop":"#/components/schemas/ContinueToolRule","exit_loop":"#/components/schemas/TerminalToolRule","max_count_per_step":"#/components/schemas/MaxCountPerStepToolRule","parent_last_tool":"#/components/schemas/ParentToolRule","run_first":"#/components/schemas/InitToolRule"}}},"type":"array"},{"type":"null"}],"title":"Tool Rules","description":"The tool rules governing the agent."},"tags":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Tags","description":"The tags associated with the agent."},"system":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"System","description":"The system prompt used by the agent."},"agent_type":{"description":"The type of agent.","type":"string","enum":["memgpt_agent","split_thread_agent","sleeptime_agent"],"title":"AgentType","x-readme-ref-name":"AgentType"},"llm_config":{"anyOf":[{"properties":{"model":{"type":"string","title":"Model","description":"LLM model name. "},"model_endpoint_type":{"type":"string","enum":["openai","anthropic","cohere","google_ai","google_vertex","azure","groq","ollama","webui","webui-legacy","lmstudio","lmstudio-legacy","lmstudio-chatcompletions","llamacpp","koboldcpp","vllm","hugging-face","mistral","together","bedrock","deepseek","xai"],"title":"Model Endpoint Type","description":"The endpoint type for the model."},"model_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model Endpoint","description":"The endpoint for the model."},"model_wrapper":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model Wrapper","description":"The wrapper for the model."},"context_window":{"type":"integer","title":"Context Window","description":"The context window size for the model."},"put_inner_thoughts_in_kwargs":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Put Inner Thoughts In Kwargs","description":"Puts 'inner_thoughts' as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts.","default":true},"handle":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Handle","description":"The handle for this config, in the format provider/model-name."},"temperature":{"type":"number","title":"Temperature","description":"The temperature to use when generating text with the model. A higher temperature will result in more random text.","default":0.7},"max_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Max Tokens","description":"The maximum number of tokens to generate. If not set, the model will use its default value.","default":4096},"enable_reasoner":{"type":"boolean","title":"Enable Reasoner","description":"Whether or not the model should use extended thinking if it is a 'reasoning' style model","default":false},"max_reasoning_tokens":{"type":"integer","title":"Max Reasoning Tokens","description":"Configurable thinking budget for extended thinking, only used if enable_reasoner is True. Minimum value is 1024.","default":0}},"type":"object","required":["model","model_endpoint_type","context_window"],"title":"LLMConfig","description":"Configuration for a Language Model (LLM) model. This object specifies all the information necessary to access an LLM model to usage with Letta, except for secret keys.\n\nAttributes:\n    model (str): The name of the LLM model.\n    model_endpoint_type (str): The endpoint type for the model.\n    model_endpoint (str): The endpoint for the model.\n    model_wrapper (str): The wrapper for the model. This is used to wrap additional text around the input/output of the model. This is useful for text-to-text completions, such as the Completions API in OpenAI.\n    context_window (int): The context window size for the model.\n    put_inner_thoughts_in_kwargs (bool): Puts `inner_thoughts` as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts.\n    temperature (float): The temperature to use when generating text with the model. A higher temperature will result in more random text.\n    max_tokens (int): The maximum number of tokens to generate.","x-readme-ref-name":"LLMConfig"},{"type":"null"}],"description":"The LLM configuration used by the agent."},"embedding_config":{"anyOf":[{"properties":{"embedding_endpoint_type":{"type":"string","enum":["openai","anthropic","bedrock","cohere","google_ai","google_vertex","azure","groq","ollama","webui","webui-legacy","lmstudio","lmstudio-legacy","llamacpp","koboldcpp","vllm","hugging-face","mistral","together"],"title":"Embedding Endpoint Type","description":"The endpoint type for the model."},"embedding_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Embedding Endpoint","description":"The endpoint for the model (`None` if local)."},"embedding_model":{"type":"string","title":"Embedding Model","description":"The model for the embedding."},"embedding_dim":{"type":"integer","title":"Embedding Dim","description":"The dimension of the embedding."},"embedding_chunk_size":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Embedding Chunk Size","description":"The chunk size of the embedding.","default":300},"handle":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Handle","description":"The handle for this config, in the format provider/model-name."},"azure_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Endpoint","description":"The Azure endpoint for the model."},"azure_version":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Version","description":"The Azure version for the model."},"azure_deployment":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Deployment","description":"The Azure deployment for the model."}},"type":"object","required":["embedding_endpoint_type","embedding_model","embedding_dim"],"title":"EmbeddingConfig","description":"Embedding model configuration. This object specifies all the information necessary to access an embedding model to usage with Letta, except for secret keys.\n\nAttributes:\n    embedding_endpoint_type (str): The endpoint type for the model.\n    embedding_endpoint (str): The endpoint for the model.\n    embedding_model (str): The model for the embedding.\n    embedding_dim (int): The dimension of the embedding.\n    embedding_chunk_size (int): The chunk size of the embedding.\n    azure_endpoint (:obj:`str`, optional): The Azure endpoint for the model (Azure only).\n    azure_version (str): The Azure version for the model (Azure only).\n    azure_deployment (str): The Azure deployment for the model (Azure only).","x-readme-ref-name":"EmbeddingConfig"},{"type":"null"}],"description":"The embedding configuration used by the agent."},"initial_message_sequence":{"anyOf":[{"items":{"properties":{"role":{"type":"string","enum":["user","system"],"title":"Role","description":"The role of the participant."},"content":{"anyOf":[{"items":{"oneOf":[{"properties":{"type":{"type":"string","const":"text","title":"Type","description":"The type of the message.","default":"text","enum":["text"]},"text":{"type":"string","title":"Text","description":"The text content of the message."}},"type":"object","required":["text","type","type","type"],"title":"TextContent","x-readme-ref-name":"TextContent"},{"properties":{"type":{"type":"string","const":"tool_call","title":"Type","description":"Indicates this content represents a tool call event.","default":"tool_call","enum":["tool_call","tool_return"]},"id":{"type":"string","title":"Id","description":"A unique identifier for this specific tool call instance."},"name":{"type":"string","title":"Name","description":"The name of the tool being called."},"input":{"additionalProperties":true,"type":"object","title":"Input","description":"The parameters being passed to the tool, structured as a dictionary of parameter names to values."}},"type":"object","required":["id","name","input","type","type"],"title":"ToolCallContent","x-readme-ref-name":"ToolCallContent"},{"properties":{"type":{"type":"string","const":"tool_return","title":"Type","description":"Indicates this content represents a tool return event.","default":"tool_return"},"tool_call_id":{"type":"string","title":"Tool Call Id","description":"References the ID of the ToolCallContent that initiated this tool call."},"content":{"type":"string","title":"Content","description":"The content returned by the tool execution."},"is_error":{"type":"boolean","title":"Is Error","description":"Indicates whether the tool execution resulted in an error."}},"type":"object","required":["tool_call_id","content","is_error"],"title":"ToolReturnContent","x-readme-ref-name":"ToolReturnContent"},{"properties":{"type":{"type":"string","const":"reasoning","title":"Type","description":"Indicates this is a reasoning/intermediate step.","default":"reasoning","enum":["reasoning"]},"is_native":{"type":"boolean","title":"Is Native","description":"Whether the reasoning content was generated by a reasoner model that processed this step."},"reasoning":{"type":"string","title":"Reasoning","description":"The intermediate reasoning or thought process content."},"signature":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Signature","description":"A unique identifier for this reasoning step."}},"type":"object","required":["is_native","reasoning","type"],"title":"ReasoningContent","x-readme-ref-name":"ReasoningContent"},{"properties":{"type":{"type":"string","const":"redacted_reasoning","title":"Type","description":"Indicates this is a redacted thinking step.","default":"redacted_reasoning","enum":["redacted_reasoning"]},"data":{"type":"string","title":"Data","description":"The redacted or filtered intermediate reasoning content."}},"type":"object","required":["data","type"],"title":"RedactedReasoningContent","x-readme-ref-name":"RedactedReasoningContent"},{"properties":{"type":{"type":"string","const":"omitted_reasoning","title":"Type","description":"Indicates this is an omitted reasoning step.","default":"omitted_reasoning","enum":["omitted_reasoning"]},"tokens":{"type":"integer","title":"Tokens","description":"The reasoning token count for intermediate reasoning content."}},"type":"object","required":["tokens","type"],"title":"OmittedReasoningContent","x-readme-ref-name":"OmittedReasoningContent"}],"discriminator":{"propertyName":"type","mapping":{"text":"#/components/schemas/TextContent","tool_call":"#/components/schemas/ToolCallContent","tool_return":"#/components/schemas/ToolCallContent","reasoning":"#/components/schemas/ReasoningContent","redacted_reasoning":"#/components/schemas/RedactedReasoningContent","omitted_reasoning":"#/components/schemas/OmittedReasoningContent"}},"x-readme-ref-name":"LettaMessageContentUnion","properties":{"type":{"enum":["text","tool_call","tool_return","reasoning","redacted_reasoning","omitted_reasoning"]}}},"type":"array"},{"type":"string"}],"title":"Content","description":"The content of the message."},"name":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Name","description":"The name of the participant."},"otid":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Otid","description":"The offline threading id associated with this message"}},"type":"object","required":["role","content"],"title":"MessageCreate","description":"Request to create a message","x-readme-ref-name":"MessageCreate"},"type":"array"},{"type":"null"}],"title":"Initial Message Sequence","description":"The initial set of messages to put in the agent's in-context memory."},"include_base_tools":{"type":"boolean","title":"Include Base Tools","description":"If true, attaches the Letta core tools (e.g. archival_memory and core_memory related functions).","default":true},"include_multi_agent_tools":{"type":"boolean","title":"Include Multi Agent Tools","description":"If true, attaches the Letta multi-agent tools (e.g. sending a message to another agent).","default":false},"include_base_tool_rules":{"type":"boolean","title":"Include Base Tool Rules","description":"If true, attaches the Letta base tool rules (e.g. deny all tools not explicitly allowed).","default":true},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description","description":"The description of the agent."},"metadata":{"anyOf":[{"additionalProperties":true,"type":"object"},{"type":"null"}],"title":"Metadata","description":"The metadata of the agent."},"model":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model","description":"The LLM configuration handle used by the agent, specified in the format provider/model-name, as an alternative to specifying llm_config."},"embedding":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Embedding","description":"The embedding configuration handle used by the agent, specified in the format provider/model-name."},"context_window_limit":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Context Window Limit","description":"The context window limit used by the agent."},"embedding_chunk_size":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Embedding Chunk Size","description":"The embedding chunk size used by the agent.","default":300},"max_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Max Tokens","description":"The maximum number of tokens to generate, including reasoning step. If not set, the model will use its default value."},"max_reasoning_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Max Reasoning Tokens","description":"The maximum number of tokens to generate for reasoning step. If not set, the model will use its default value."},"enable_reasoner":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Enable Reasoner","description":"Whether to enable internal extended thinking step for a reasoner model.","default":false},"from_template":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"From Template","description":"The template id used to configure the agent"},"template":{"type":"boolean","title":"Template","description":"Whether the agent is a template","default":false},"project":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Project","description":"Deprecated: Project should now be passed via the X-Project header instead of in the request body. If using the sdk, this can be done via the new x_project field below.","deprecated":true},"tool_exec_environment_variables":{"anyOf":[{"additionalProperties":{"type":"string"},"type":"object"},{"type":"null"}],"title":"Tool Exec Environment Variables","description":"The environment variables for tool execution specific to this agent."},"memory_variables":{"anyOf":[{"additionalProperties":{"type":"string"},"type":"object"},{"type":"null"}],"title":"Memory Variables","description":"The variables that should be set for the agent."},"project_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Project Id","description":"The id of the project the agent belongs to."},"template_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Template Id","description":"The id of the template the agent belongs to."},"base_template_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Base Template Id","description":"The base template id of the agent."},"identity_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Identity Ids","description":"The ids of the identities associated with this agent."},"message_buffer_autoclear":{"type":"boolean","title":"Message Buffer Autoclear","description":"If set to True, the agent will not remember previous messages (though the agent will still retain state via core memory blocks and archival/recall memory). Not recommended unless you have an advanced use case.","default":false},"enable_sleeptime":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Enable Sleeptime","description":"If set to True, memory management will move to a background agent thread."}},"type":"object","title":"CreateAgentRequest","description":"CreateAgent model specifically for POST request body, excluding user_id which comes from headers","x-readme-ref-name":"CreateAgentRequest"}