{"properties":{"name":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Name","description":"The name of the agent."},"tool_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Tool Ids","description":"The ids of the tools used by the agent."},"source_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Source Ids","description":"The ids of the sources used by the agent."},"block_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Block Ids","description":"The ids of the blocks used by the agent."},"tags":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Tags","description":"The tags associated with the agent."},"system":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"System","description":"The system prompt used by the agent."},"tool_rules":{"anyOf":[{"items":{"oneOf":[{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"constrain_child_tools","title":"Type","default":"constrain_child_tools"},"children":{"items":{"type":"string"},"type":"array","title":"Children","description":"The children tools that can be invoked."}},"additionalProperties":false,"type":"object","required":["tool_name","children"],"title":"ChildToolRule","description":"A ToolRule represents a tool that can be invoked by the agent.","x-readme-ref-name":"ChildToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"run_first","title":"Type","default":"run_first"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"InitToolRule","description":"Represents the initial tool rule configuration.","x-readme-ref-name":"InitToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"exit_loop","title":"Type","default":"exit_loop"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"TerminalToolRule","description":"Represents a terminal tool rule configuration where if this tool gets called, it must end the agent loop.","x-readme-ref-name":"TerminalToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"conditional","title":"Type","default":"conditional"},"default_child":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Default Child","description":"The default child tool to be called. If None, any tool can be called."},"child_output_mapping":{"additionalProperties":{"type":"string"},"type":"object","title":"Child Output Mapping","description":"The output case to check for mapping"},"require_output_mapping":{"type":"boolean","title":"Require Output Mapping","description":"Whether to throw an error when output doesn't match any case","default":false}},"additionalProperties":false,"type":"object","required":["tool_name","child_output_mapping"],"title":"ConditionalToolRule","description":"A ToolRule that conditionally maps to different child tools based on the output.","x-readme-ref-name":"ConditionalToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"continue_loop","title":"Type","default":"continue_loop"}},"additionalProperties":false,"type":"object","required":["tool_name"],"title":"ContinueToolRule","description":"Represents a tool rule configuration where if this tool gets called, it must continue the agent loop.","x-readme-ref-name":"ContinueToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"max_count_per_step","title":"Type","default":"max_count_per_step"},"max_count_limit":{"type":"integer","title":"Max Count Limit","description":"The max limit for the total number of times this tool can be invoked in a single step."}},"additionalProperties":false,"type":"object","required":["tool_name","max_count_limit"],"title":"MaxCountPerStepToolRule","description":"Represents a tool rule configuration which constrains the total number of times this tool can be invoked in a single step.","x-readme-ref-name":"MaxCountPerStepToolRule"},{"properties":{"tool_name":{"type":"string","title":"Tool Name","description":"The name of the tool. Must exist in the database for the user's organization."},"type":{"type":"string","const":"parent_last_tool","title":"Type","default":"parent_last_tool"},"children":{"items":{"type":"string"},"type":"array","title":"Children","description":"The children tools that can be invoked."}},"additionalProperties":false,"type":"object","required":["tool_name","children"],"title":"ParentToolRule","description":"A ToolRule that only allows a child tool to be called if the parent has been called.","x-readme-ref-name":"ParentToolRule"}],"discriminator":{"propertyName":"type","mapping":{"conditional":"#/components/schemas/ConditionalToolRule","constrain_child_tools":"#/components/schemas/ChildToolRule","continue_loop":"#/components/schemas/ContinueToolRule","exit_loop":"#/components/schemas/TerminalToolRule","max_count_per_step":"#/components/schemas/MaxCountPerStepToolRule","parent_last_tool":"#/components/schemas/ParentToolRule","run_first":"#/components/schemas/InitToolRule"}}},"type":"array"},{"type":"null"}],"title":"Tool Rules","description":"The tool rules governing the agent."},"llm_config":{"anyOf":[{"properties":{"model":{"type":"string","title":"Model","description":"LLM model name. "},"model_endpoint_type":{"type":"string","enum":["openai","anthropic","cohere","google_ai","google_vertex","azure","groq","ollama","webui","webui-legacy","lmstudio","lmstudio-legacy","lmstudio-chatcompletions","llamacpp","koboldcpp","vllm","hugging-face","mistral","together","bedrock","deepseek","xai"],"title":"Model Endpoint Type","description":"The endpoint type for the model."},"model_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model Endpoint","description":"The endpoint for the model."},"model_wrapper":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model Wrapper","description":"The wrapper for the model."},"context_window":{"type":"integer","title":"Context Window","description":"The context window size for the model."},"put_inner_thoughts_in_kwargs":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Put Inner Thoughts In Kwargs","description":"Puts 'inner_thoughts' as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts.","default":true},"handle":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Handle","description":"The handle for this config, in the format provider/model-name."},"temperature":{"type":"number","title":"Temperature","description":"The temperature to use when generating text with the model. A higher temperature will result in more random text.","default":0.7},"max_tokens":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Max Tokens","description":"The maximum number of tokens to generate. If not set, the model will use its default value.","default":4096},"enable_reasoner":{"type":"boolean","title":"Enable Reasoner","description":"Whether or not the model should use extended thinking if it is a 'reasoning' style model","default":false},"max_reasoning_tokens":{"type":"integer","title":"Max Reasoning Tokens","description":"Configurable thinking budget for extended thinking, only used if enable_reasoner is True. Minimum value is 1024.","default":0}},"type":"object","required":["model","model_endpoint_type","context_window"],"title":"LLMConfig","description":"Configuration for a Language Model (LLM) model. This object specifies all the information necessary to access an LLM model to usage with Letta, except for secret keys.\n\nAttributes:\n    model (str): The name of the LLM model.\n    model_endpoint_type (str): The endpoint type for the model.\n    model_endpoint (str): The endpoint for the model.\n    model_wrapper (str): The wrapper for the model. This is used to wrap additional text around the input/output of the model. This is useful for text-to-text completions, such as the Completions API in OpenAI.\n    context_window (int): The context window size for the model.\n    put_inner_thoughts_in_kwargs (bool): Puts `inner_thoughts` as a kwarg in the function call if this is set to True. This helps with function calling performance and also the generation of inner thoughts.\n    temperature (float): The temperature to use when generating text with the model. A higher temperature will result in more random text.\n    max_tokens (int): The maximum number of tokens to generate.","x-readme-ref-name":"LLMConfig"},{"type":"null"}],"description":"The LLM configuration used by the agent."},"embedding_config":{"anyOf":[{"properties":{"embedding_endpoint_type":{"type":"string","enum":["openai","anthropic","bedrock","cohere","google_ai","google_vertex","azure","groq","ollama","webui","webui-legacy","lmstudio","lmstudio-legacy","llamacpp","koboldcpp","vllm","hugging-face","mistral","together"],"title":"Embedding Endpoint Type","description":"The endpoint type for the model."},"embedding_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Embedding Endpoint","description":"The endpoint for the model (`None` if local)."},"embedding_model":{"type":"string","title":"Embedding Model","description":"The model for the embedding."},"embedding_dim":{"type":"integer","title":"Embedding Dim","description":"The dimension of the embedding."},"embedding_chunk_size":{"anyOf":[{"type":"integer"},{"type":"null"}],"title":"Embedding Chunk Size","description":"The chunk size of the embedding.","default":300},"handle":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Handle","description":"The handle for this config, in the format provider/model-name."},"azure_endpoint":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Endpoint","description":"The Azure endpoint for the model."},"azure_version":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Version","description":"The Azure version for the model."},"azure_deployment":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Azure Deployment","description":"The Azure deployment for the model."}},"type":"object","required":["embedding_endpoint_type","embedding_model","embedding_dim"],"title":"EmbeddingConfig","description":"Embedding model configuration. This object specifies all the information necessary to access an embedding model to usage with Letta, except for secret keys.\n\nAttributes:\n    embedding_endpoint_type (str): The endpoint type for the model.\n    embedding_endpoint (str): The endpoint for the model.\n    embedding_model (str): The model for the embedding.\n    embedding_dim (int): The dimension of the embedding.\n    embedding_chunk_size (int): The chunk size of the embedding.\n    azure_endpoint (:obj:`str`, optional): The Azure endpoint for the model (Azure only).\n    azure_version (str): The Azure version for the model (Azure only).\n    azure_deployment (str): The Azure deployment for the model (Azure only).","x-readme-ref-name":"EmbeddingConfig"},{"type":"null"}],"description":"The embedding configuration used by the agent."},"message_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Message Ids","description":"The ids of the messages in the agent's in-context memory."},"description":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Description","description":"The description of the agent."},"metadata":{"anyOf":[{"additionalProperties":true,"type":"object"},{"type":"null"}],"title":"Metadata","description":"The metadata of the agent."},"tool_exec_environment_variables":{"anyOf":[{"additionalProperties":{"type":"string"},"type":"object"},{"type":"null"}],"title":"Tool Exec Environment Variables","description":"The environment variables for tool execution specific to this agent."},"project_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Project Id","description":"The id of the project the agent belongs to."},"template_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Template Id","description":"The id of the template the agent belongs to."},"base_template_id":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Base Template Id","description":"The base template id of the agent."},"identity_ids":{"anyOf":[{"items":{"type":"string"},"type":"array"},{"type":"null"}],"title":"Identity Ids","description":"The ids of the identities associated with this agent."},"message_buffer_autoclear":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Message Buffer Autoclear","description":"If set to True, the agent will not remember previous messages (though the agent will still retain state via core memory blocks and archival/recall memory). Not recommended unless you have an advanced use case."},"model":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Model","description":"The LLM configuration handle used by the agent, specified in the format provider/model-name, as an alternative to specifying llm_config."},"embedding":{"anyOf":[{"type":"string"},{"type":"null"}],"title":"Embedding","description":"The embedding configuration handle used by the agent, specified in the format provider/model-name."},"enable_sleeptime":{"anyOf":[{"type":"boolean"},{"type":"null"}],"title":"Enable Sleeptime","description":"If set to True, memory management will move to a background agent thread."}},"type":"object","title":"UpdateAgent","x-readme-ref-name":"UpdateAgent"}